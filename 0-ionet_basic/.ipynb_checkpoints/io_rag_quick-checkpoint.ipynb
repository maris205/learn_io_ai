{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e52f0ad7-9069-45a4-8285-a2f5fbdb86a8",
   "metadata": {},
   "source": [
    "## ionet RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da45fda9-5a80-4216-a9a1-fd5135db34d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting r2r\n",
      "  Downloading r2r-3.6.6-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting aiofiles<25.0.0,>=24.1.0 (from r2r)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting alembic<2.0.0,>=1.13.3 (from r2r)\n",
      "  Downloading alembic-1.16.5-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting fastapi<0.116.0,>=0.115.11 (from r2r)\n",
      "  Downloading fastapi-0.115.14-py3-none-any.whl.metadata (27 kB)\n",
      "Requirement already satisfied: httpx>=0.27.0 in f:\\conda\\envs\\ionet\\lib\\site-packages (from r2r) (0.28.1)\n",
      "Requirement already satisfied: openai>=1.99.0 in f:\\conda\\envs\\ionet\\lib\\site-packages (from r2r) (1.100.2)\n",
      "Collecting python-dotenv<2.0.0,>=1.0.1 (from r2r)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Collecting psycopg-binary<4.0.0,>=3.2.3 (from r2r)\n",
      "  Downloading psycopg_binary-3.2.9-cp311-cp311-win_amd64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in f:\\conda\\envs\\ionet\\lib\\site-packages (from r2r) (2.32.5)\n",
      "Collecting tiktoken<0.9.0,>=0.8.0 (from r2r)\n",
      "  Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting toml<0.11.0,>=0.10.2 (from r2r)\n",
      "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting types-requests<3.0.0,>=2.31.0 (from r2r)\n",
      "  Downloading types_requests-2.32.4.20250809-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting types-aiofiles<25.0.0,>=24.1.0.20240626 (from r2r)\n",
      "  Downloading types_aiofiles-24.1.0.20250822-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.12.2 in f:\\conda\\envs\\ionet\\lib\\site-packages (from r2r) (4.14.1)\n",
      "Requirement already satisfied: pydantic>=2.10.6 in f:\\conda\\envs\\ionet\\lib\\site-packages (from r2r) (2.11.7)\n",
      "Collecting python-json-logger>=3.2.1 (from r2r)\n",
      "  Using cached python_json_logger-3.3.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting filetype>=1.2.0 (from r2r)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting SQLAlchemy>=1.4.0 (from alembic<2.0.0,>=1.13.3->r2r)\n",
      "  Downloading sqlalchemy-2.0.43-cp311-cp311-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting Mako (from alembic<2.0.0,>=1.13.3->r2r)\n",
      "  Downloading mako-1.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi<0.116.0,>=0.115.11->r2r)\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in f:\\conda\\envs\\ionet\\lib\\site-packages (from pydantic>=2.10.6->r2r) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in f:\\conda\\envs\\ionet\\lib\\site-packages (from pydantic>=2.10.6->r2r) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in f:\\conda\\envs\\ionet\\lib\\site-packages (from pydantic>=2.10.6->r2r) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in f:\\conda\\envs\\ionet\\lib\\site-packages (from requests<3.0.0,>=2.31.0->r2r) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in f:\\conda\\envs\\ionet\\lib\\site-packages (from requests<3.0.0,>=2.31.0->r2r) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in f:\\conda\\envs\\ionet\\lib\\site-packages (from requests<3.0.0,>=2.31.0->r2r) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in f:\\conda\\envs\\ionet\\lib\\site-packages (from requests<3.0.0,>=2.31.0->r2r) (2025.8.3)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in f:\\conda\\envs\\ionet\\lib\\site-packages (from starlette<0.47.0,>=0.40.0->fastapi<0.116.0,>=0.115.11->r2r) (4.10.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in f:\\conda\\envs\\ionet\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi<0.116.0,>=0.115.11->r2r) (1.3.1)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<0.9.0,>=0.8.0->r2r)\n",
      "  Downloading regex-2025.9.1-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "Requirement already satisfied: httpcore==1.* in f:\\conda\\envs\\ionet\\lib\\site-packages (from httpx>=0.27.0->r2r) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in f:\\conda\\envs\\ionet\\lib\\site-packages (from httpcore==1.*->httpx>=0.27.0->r2r) (0.16.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in f:\\conda\\envs\\ionet\\lib\\site-packages (from openai>=1.99.0->r2r) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in f:\\conda\\envs\\ionet\\lib\\site-packages (from openai>=1.99.0->r2r) (0.10.0)\n",
      "Requirement already satisfied: tqdm>4 in f:\\conda\\envs\\ionet\\lib\\site-packages (from openai>=1.99.0->r2r) (4.67.1)\n",
      "Collecting greenlet>=1 (from SQLAlchemy>=1.4.0->alembic<2.0.0,>=1.13.3->r2r)\n",
      "  Downloading greenlet-3.2.4-cp311-cp311-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: colorama in f:\\conda\\envs\\ionet\\lib\\site-packages (from tqdm>4->openai>=1.99.0->r2r) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in f:\\conda\\envs\\ionet\\lib\\site-packages (from Mako->alembic<2.0.0,>=1.13.3->r2r) (3.0.2)\n",
      "Downloading r2r-3.6.6-py3-none-any.whl (514 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading alembic-1.16.5-py3-none-any.whl (247 kB)\n",
      "Downloading fastapi-0.115.14-py3-none-any.whl (95 kB)\n",
      "Downloading psycopg_binary-3.2.9-cp311-cp311-win_amd64.whl (2.9 MB)\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.3/2.9 MB ? eta -:--:--\n",
      "   ------- -------------------------------- 0.5/2.9 MB 509.0 kB/s eta 0:00:05\n",
      "   -------------- ------------------------- 1.0/2.9 MB 968.5 kB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 1.3/2.9 MB 1.2 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 1.8/2.9 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 2.1/2.9 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 2.4/2.9 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.6/2.9 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.9/2.9 MB 1.4 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Downloading tiktoken-0.8.0-cp311-cp311-win_amd64.whl (884 kB)\n",
      "   ---------------------------------------- 0.0/884.5 kB ? eta -:--:--\n",
      "   ----------- ---------------------------- 262.1/884.5 kB ? eta -:--:--\n",
      "   ---------------------------------------- 884.5/884.5 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Downloading types_aiofiles-24.1.0.20250822-py3-none-any.whl (14 kB)\n",
      "Downloading types_requests-2.32.4.20250809-py3-none-any.whl (20 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Using cached python_json_logger-3.3.0-py3-none-any.whl (15 kB)\n",
      "Downloading regex-2025.9.1-cp311-cp311-win_amd64.whl (276 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.1 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.1 MB 2.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 2.0 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.2.4-cp311-cp311-win_amd64.whl (299 kB)\n",
      "Downloading mako-1.3.10-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: filetype, types-requests, types-aiofiles, toml, regex, python-json-logger, python-dotenv, psycopg-binary, Mako, greenlet, aiofiles, tiktoken, starlette, SQLAlchemy, fastapi, alembic, r2r\n",
      "\n",
      "   --------- ------------------------------  4/17 [regex]\n",
      "  Attempting uninstall: python-json-logger\n",
      "   --------- ------------------------------  4/17 [regex]\n",
      "    Found existing installation: python-json-logger 2.0.7\n",
      "   --------- ------------------------------  4/17 [regex]\n",
      "    Uninstalling python-json-logger-2.0.7:\n",
      "   --------- ------------------------------  4/17 [regex]\n",
      "      Successfully uninstalled python-json-logger-2.0.7\n",
      "   --------- ------------------------------  4/17 [regex]\n",
      "   ----------- ----------------------------  5/17 [python-json-logger]\n",
      "   ------------------ ---------------------  8/17 [Mako]\n",
      "   --------------------- ------------------  9/17 [greenlet]\n",
      "   ----------------------- ---------------- 10/17 [aiofiles]\n",
      "   ---------------------------- ----------- 12/17 [starlette]\n",
      "   ---------------------------- ----------- 12/17 [starlette]\n",
      "   ------------------------------ --------- 13/17 [SQLAlchemy]\n",
      "   ------------------------------ --------- 13/17 [SQLAlchemy]\n",
      "   ------------------------------ --------- 13/17 [SQLAlchemy]\n",
      "   ------------------------------ --------- 13/17 [SQLAlchemy]\n",
      "   ------------------------------ --------- 13/17 [SQLAlchemy]\n",
      "   ------------------------------ --------- 13/17 [SQLAlchemy]\n",
      "   ------------------------------ --------- 13/17 [SQLAlchemy]\n",
      "   ------------------------------ --------- 13/17 [SQLAlchemy]\n",
      "   ------------------------------ --------- 13/17 [SQLAlchemy]\n",
      "   ------------------------------ --------- 13/17 [SQLAlchemy]\n",
      "   -------------------------------- ------- 14/17 [fastapi]\n",
      "   ----------------------------------- ---- 15/17 [alembic]\n",
      "   ----------------------------------- ---- 15/17 [alembic]\n",
      "   ----------------------------------- ---- 15/17 [alembic]\n",
      "   ------------------------------------- -- 16/17 [r2r]\n",
      "   ------------------------------------- -- 16/17 [r2r]\n",
      "   ------------------------------------- -- 16/17 [r2r]\n",
      "   ------------------------------------- -- 16/17 [r2r]\n",
      "   ---------------------------------------- 17/17 [r2r]\n",
      "\n",
      "Successfully installed Mako-1.3.10 SQLAlchemy-2.0.43 aiofiles-24.1.0 alembic-1.16.5 fastapi-0.115.14 filetype-1.2.0 greenlet-3.2.4 psycopg-binary-3.2.9 python-dotenv-1.1.1 python-json-logger-3.3.0 r2r-3.6.6 regex-2025.9.1 starlette-0.46.2 tiktoken-0.8.0 toml-0.10.2 types-aiofiles-24.1.0.20250822 types-requests-2.32.4.20250809\n"
     ]
    }
   ],
   "source": [
    "!pip install r2r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c74346c-0e45-4658-9bed-9f126aba6ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from r2r import R2RClient\n",
    "client = R2RClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "971b45fb-0e93-4895-b9da-53f3995d1956",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.set_base_url(\"https://api.intelligence.io.solutions/api/r2r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1921f56b-97b6-4029-b4fc-28861af04004",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.access_token = \"io-v2-eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCJ9.eyJvd25lciI6IjAzNzRhMjJjLTVmZTctNDBhNS04OGU4LTEwMjk3MGViMjEyNiIsImV4cCI6NDkwNTc2MTYyM30.F2HzmnMxRaHpRh2kfPRSgp7JHqtVb5BUmZD4kz1TxY28Usvyh18shHpNpvmncoE8S-IvZH3qlEEScNtO9j-5Dw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b95ed83-a1e0-43ca-98e0-910f350b18fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R2RResults[GenericMessageResponse](results=GenericMessageResponse(message='ok'))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.system.health()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc17610d-308c-4606-9e80-1fc181d6af33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R2RResults[IngestionResponse](results=IngestionResponse(message='Ingest files task queued successfully.', task_id=UUID('a45d1a58-3063-49ab-acb6-0da7a83173fa'), document_id=UUID('0f5a9012-115f-51cb-8266-df32e1ad6f54')))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.documents.create(file_path=\"deepseek.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc9281e6-ebd1-4e6f-9435-7472e783d2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PaginatedR2RResult[list[DocumentResponse]](results=[DocumentResponse(id=UUID('0f5a9012-115f-51cb-8266-df32e1ad6f54'), collection_ids=[], owner_id=UUID('5c74c15c-ca5c-5213-94c4-5648938da6be'), document_type=<DocumentType.TXT: 'txt'>, metadata={'version': 'v0'}, title='deepseek.txt', version='v0', size_in_bytes=701, ingestion_status=<IngestionStatus.AUGMENTING: 'augmenting'>, extraction_status=<GraphExtractionStatus.PENDING: 'pending'>, created_at=datetime.datetime(2025, 9, 4, 7, 44, 56, 8982, tzinfo=TzInfo(UTC)), updated_at=datetime.datetime(2025, 9, 4, 7, 44, 56, 796398, tzinfo=TzInfo(UTC)), ingestion_attempt_number=None, summary=None, summary_embedding=None, total_tokens=182, chunks=None)], total_entries=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.documents.list()\n",
    "# to ingest your own document, client.documents.create(file_path=\"/path/to/file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8065dc0d-08d6-4632-a42b-c38f025af894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R2RResults[AggregateSearchResult](results=AggregateSearchResult(chunk_search_results=[ChunkSearchResult(score=0.647, text=DeepSeek 是一家中国人工智能初创公司，专注于开发高效的大型语言模型（LLM）。它成立于2023年，由一群前Google DeepMind等机构的AI研究者创立。公司致力于开源AI技术，其代表性产品包括：DeepSeek\n",
       "\n",
       "V2：一个236B参数的混合专家（MoE）模型，激活参数仅16B，支持多语言和长上下文处理，在数学、代码生成和推理任务上性能出色，与闭源模型如GPT\n",
       "\n",
       "4竞争。\n",
       "\n",
       "DeepSeek\n",
       "\n",
       "Coder：专注于编程领域的模型，支持多种编程语言，提供代码补全、调试等功能。\n",
       "\n",
       "DeepSeek 的模型强调高效性和可访问性，已在Hugging Face等平台开源，广泛用于研究和应用开发。)], graph_search_results=[], web_page_search_results=None, web_search_results=None, document_search_results=None, generic_tool_result=None))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.retrieval.search(\n",
    "  query=\"deepseek是不是开源的\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21a90fba-aa9b-4621-9740-9bfe196e4ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = client.retrieval.rag(\n",
    "  query=\"deepseek是不是开源的\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24410219-6ffd-4c45-a6b9-72e2d1f431e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'根据搜索结果 [dd9c3ca]，DeepSeek 致力于开源 AI 技术，其代表性产品包括 DeepSeek V2 和 DeepSeek Coder，且这些模型已在 Hugging Face 等平台开源。因此，DeepSeek 是开源的。'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret.results.generated_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "12019851-bc97-481e-afe9-560498830b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search results: id='search_1' object='rag.search_results' data=AggregateSearchResult(chunk_search_results=[ChunkSearchResult(score=0.647, text=DeepSeek 是一家中国人工智能初创公司，专注于开发高效的大型语言模型（LLM）。它成立于2023年，由一群前Google DeepMind等机构的AI研究者创立。公司致力于开源AI技术，其代表性产品包括：DeepSeek\n",
      "\n",
      "V2：一个236B参数的混合专家（MoE）模型，激活参数仅16B，支持多语言和长上下文处理，在数学、代码生成和推理任务上性能出色，与闭源模型如GPT\n",
      "\n",
      "4竞争。\n",
      "\n",
      "DeepSeek\n",
      "\n",
      "Coder：专注于编程领域的模型，支持多种编程语言，提供代码补全、调试等功能。\n",
      "\n",
      "DeepSeek 的模型强调高效性和可访问性，已在Hugging Face等平台开源，广泛用于研究和应用开发。)], graph_search_results=[], web_page_search_results=None, web_search_results=[], document_search_results=[], generic_tool_result=None)\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='根据', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='搜索', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='结果', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=' [', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='dd', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='9', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='c', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='3', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='ca', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=']', annotations=[]))]\n",
      "New citation detected: id='dd9c3ca' object='citation' is_new=True span=CitationSpanData(start=7, end=16, context_start=None, context_end=None) source_type=None payload={'id': 'dd9c3ca2-b95f-5d62-8841-b63efbb1e003', 'document_id': '0f5a9012-115f-51cb-8266-df32e1ad6f54', 'owner_id': '5c74c15c-ca5c-5213-94c4-5648938da6be', 'collection_ids': ['55a5a12f-1f44-5474-a01a-75d799785bd8'], 'score': 0.646823665987462, 'text': 'DeepSeek 是一家中国人工智能初创公司，专注于开发高效的大型语言模型（LLM）。它成立于2023年，由一群前Google DeepMind等机构的AI研究者创立。公司致力于开源AI技术，其代表性产品包括：DeepSeek\\n\\nV2：一个236B参数的混合专家（MoE）模型，激活参数仅16B，支持多语言和长上下文处理，在数学、代码生成和推理任务上性能出色，与闭源模型如GPT\\n\\n4竞争。\\n\\nDeepSeek\\n\\nCoder：专注于编程领域的模型，支持多种编程语言，提供代码补全、调试等功能。\\n\\nDeepSeek 的模型强调高效性和可访问性，已在Hugging Face等平台开源，广泛用于研究和应用开发。', 'metadata': {'version': 'v0', 'chunk_order': 0, 'document_type': 'txt', 'unstructured_filetype': 'text/plain', 'unstructured_languages': ['zho'], 'partitioned_by_unstructured': True, 'associated_query': 'deepseek是不是开源的'}}\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='，', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='Deep', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='Seek', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=' 致', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='力', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='于', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='开', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='源', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=' AI', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=' 技', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='术', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='，其', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='代表', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='性', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='产品', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='包括', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=' Deep', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='Seek', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=' V', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='2', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=' 和', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=' Deep', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='Seek', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=' C', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='oder', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='，', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='且', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='这些', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='模型', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='已', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='在', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=' H', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='ugging', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=' Face', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=' 等', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='平台', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='开', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='源', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='。', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='因此', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='，', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='Deep', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='Seek', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value=' 是', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='开', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='源', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='的', annotations=[]))]\n",
      "Partial message: content=[MessageDelta(type='text', payload=DeltaPayload(value='。', annotations=[]))]\n",
      "Final answer: 根据搜索结果 [dd9c3ca]，DeepSeek 致力于开源 AI 技术，其代表性产品包括 DeepSeek V2 和 DeepSeek Coder，且这些模型已在 Hugging Face 等平台开源。因此，DeepSeek 是开源的。\n"
     ]
    }
   ],
   "source": [
    "from r2r import (\n",
    "    CitationEvent,\n",
    "    FinalAnswerEvent,\n",
    "    MessageEvent,\n",
    "    SearchResultsEvent,\n",
    "    R2RClient,\n",
    ")\n",
    "\n",
    "\n",
    "result_stream = client.retrieval.rag(\n",
    "    query=\"deepseek是不是开源的\",\n",
    "    search_settings={\"limit\": 25},\n",
    "    rag_generation_config={\"stream\": True},\n",
    ")\n",
    "\n",
    "# can also do a switch on `type` field\n",
    "for event in result_stream:\n",
    "    if isinstance(event, SearchResultsEvent):\n",
    "        print(\"Search results:\", event.data)\n",
    "    elif isinstance(event, MessageEvent):\n",
    "        print(\"Partial message:\", event.data.delta)\n",
    "    elif isinstance(event, CitationEvent):\n",
    "        print(\"New citation detected:\", event.data)\n",
    "    elif isinstance(event, FinalAnswerEvent):\n",
    "        print(\"Final answer:\", event.data.generated_answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87678b4-9cd8-4b80-a7e7-c6c13ed130e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
